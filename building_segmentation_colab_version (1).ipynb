{"cells":[{"cell_type":"markdown","id":"d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914","metadata":{"id":"d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914"},"source":["## Import"]},{"cell_type":"code","execution_count":1,"id":"ad9b681e-370a-4cfa-a452-dd2d7f0cd77f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28612,"status":"ok","timestamp":1690016294582,"user":{"displayName":"박상우(인공지능융합대학 컴퓨터과학과)","userId":"12478114581481068237"},"user_tz":-540},"id":"ad9b681e-370a-4cfa-a452-dd2d7f0cd77f","outputId":"81b15f28-fbad-4bb3-b964-46461543a988"},"outputs":[],"source":["import os\n","import cv2\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torchvision import transforms\n","from torch.utils.tensorboard import SummaryWriter\n","# !pip install segmentation_models_pytorch\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","# from google.colab import drive\n","# !pip install transformers"]},{"cell_type":"code","execution_count":2,"id":"sT9MH_VAFmp6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21990,"status":"ok","timestamp":1690016320179,"user":{"displayName":"박상우(인공지능융합대학 컴퓨터과학과)","userId":"12478114581481068237"},"user_tz":-540},"id":"sT9MH_VAFmp6","outputId":"5f47aa24-74c2-4b64-f2d9-7dded74edaea"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# drive.mount('/content/drive')\n","from transformers import SamModel, SamProcessor, SamImageProcessor\n","import segmentation_models_pytorch as smp\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","# !pip install monai"]},{"cell_type":"code","execution_count":3,"id":"NOeIbRqFE6A7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1690016376786,"user":{"displayName":"박상우(인공지능융합대학 컴퓨터과학과)","userId":"12478114581481068237"},"user_tz":-540},"id":"NOeIbRqFE6A7","outputId":"19c9d4b7-90cc-4e35-86fc-90fad3d0b43c"},"outputs":[],"source":["# cd drive/MyDrive/building_segmentation"]},{"cell_type":"code","execution_count":4,"id":"54fa6afe","metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1690016378538,"user":{"displayName":"박상우(인공지능융합대학 컴퓨터과학과)","userId":"12478114581481068237"},"user_tz":-540},"id":"54fa6afe"},"outputs":[],"source":["# RLE 디코딩 함수\n","def rle_decode(mask_rle, shape):\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape)\n","\n","# RLE 인코딩 함수\n","def rle_encode(mask):\n","    pixels = mask.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)"]},{"cell_type":"code","execution_count":5,"id":"f954f274","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":656},"executionInfo":{"elapsed":954,"status":"error","timestamp":1689994525341,"user":{"displayName":"박상우(인공지능융합대학 컴퓨터과학과)","userId":"12478114581481068237"},"user_tz":-540},"id":"f954f274","outputId":"91aa457f-24ac-4ef3-9ded-5682f58bbb69"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-491273331488>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mground_truth_seg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mshow_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth_seg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def show_mask(mask, ax, random_color=False):\n","    if random_color:\n","        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n","    else:\n","        color = np.array([30/255, 144/255, 255/255, 0.6])\n","    h, w = mask.shape[-2:]\n","    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n","    ax.imshow(mask_image)\n","\n","fig, axes = plt.subplots()\n","\n","axes.imshow(np.array(image))\n","ground_truth_seg = np.array(example[\"label\"])\n","show_mask(ground_truth_seg, axes)\n","axes.title.set_text(f\"Ground truth mask\")\n","axes.axis(\"off\")"]},{"cell_type":"code","execution_count":5,"id":"5dca86ba","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1690016381980,"user":{"displayName":"박상우(인공지능융합대학 컴퓨터과학과)","userId":"12478114581481068237"},"user_tz":-540},"id":"5dca86ba"},"outputs":[],"source":["def create_prompt(ground_truth_mask):\n","    y_indices, x_indices = np.where(ground_truth_mask == 1)\n","    print(y_indices)\n","    print(x_indices)\n","    x_min, x_max = np.min(x_indices), np.max(x_indices)\n","    y_min, y_max = np.min(y_indices), np.max(y_indices)\n","    # add perturbation to bounding box coordinates\n","    H, W = ground_truth_mask.shape\n","    x_min = max(0, x_min - np.random.randint(0, 20))\n","    x_max = min(W, x_max + np.random.randint(0, 20))\n","    y_min = max(0, y_min - np.random.randint(0, 20))\n","    y_max = min(H, y_max + np.random.randint(0, 20))\n","    bbox = [x_min, y_min, x_max, y_max]\n","\n","    return bbox"]},{"cell_type":"markdown","id":"20ff3de5-0d0e-497b-ac75-d5179a3f65d3","metadata":{"id":"20ff3de5-0d0e-497b-ac75-d5179a3f65d3"},"source":["## Utils"]},{"cell_type":"code","execution_count":6,"id":"838e1d83-8670-407b-82f6-bf9652f58639","metadata":{"executionInfo":{"elapsed":281,"status":"ok","timestamp":1690016384287,"user":{"displayName":"박상우(인공지능융합대학 컴퓨터과학과)","userId":"12478114581481068237"},"user_tz":-540},"id":"838e1d83-8670-407b-82f6-bf9652f58639"},"outputs":[],"source":["class SatelliteDataset(Dataset):\n","    def __init__(self, csv_file, processor=None, transform = None, infer=False):\n","        self.data = pd.read_csv(csv_file)\n","        self.processor = processor\n","        self.infer = infer\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.data.iloc[idx, 1]\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        mask_rle = self.data.iloc[idx, 2]\n","        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n","        bbox = create_prompt(mask)\n","\n","        resize = self.transform(image = image, mask = mask)\n","        mask = resize[\"mask\"]\n","\n","        augmented = self.processor(image, input_boxes=[[bbox]], return_tensors=\"pt\")\n","        augmented = {k:v.squeeze(0) for k,v in augmented.items()}\n","        augmented[\"mask\"] = mask\n","\n","        return augmented"]},{"cell_type":"markdown","id":"be76a29e-e9c2-411a-a569-04166f074184","metadata":{"id":"be76a29e-e9c2-411a-a569-04166f074184"},"source":["## Custom Dataset"]},{"cell_type":"code","execution_count":7,"id":"a8496767-2f64-4285-bec4-c6f53a1fd9d2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["b237982e68604a219a327957adf3dbd1","51f3e742ffd84793b5dfcb319dfc6677","d6bdb4107af24ca8b73bb3f405b3cbec","de0ab2ee3636441aafbec0cd680b76eb","62480e98a3fa4cf3a2de6331f06790a0","61956ae95d074178af64b5e533cbe4da","6ec2281e00e84edba6db004e52eb6a82","ffe648c796574e54a65e050e60774650","ab2e1240643249de8be662a5f5ddd481","b6a8b52314d74cae87960c26876066bb","738e5be11e0e453b92fdaaa92d9d4cb7"]},"executionInfo":{"elapsed":2705,"status":"ok","timestamp":1690016389906,"user":{"displayName":"박상우(인공지능융합대학 컴퓨터과학과)","userId":"12478114581481068237"},"user_tz":-540},"id":"a8496767-2f64-4285-bec4-c6f53a1fd9d2","outputId":"a829ebd2-40bc-4fe7-b091-65d929fad486"},"outputs":[],"source":["from transformers import SamImageProcessor\n","\n","processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n","transform = A.Compose(\n","    [\n","        A.Resize(256, 256),\n","        ToTensorV2()\n","    ]\n",")\n","train_csv_path = \"train.csv\"\n","dataset = SatelliteDataset(train_csv_path, processor=processor, transform = transform)\n","train_dataset_length = int(len(dataset) * 0.9)\n","validation_dataset_length = int(len(dataset) * 0.1)\n","\n","train_dataset, validation_dataset = random_split(dataset, [train_dataset_length, validation_dataset_length])\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n","validation_dataloader = DataLoader(validation_dataset, batch_size=12, shuffle=True)"]},{"cell_type":"markdown","id":"dc955893-22fd-4320-88be-7aa0d790cbd9","metadata":{"id":"dc955893-22fd-4320-88be-7aa0d790cbd9"},"source":["## Data Loader"]},{"cell_type":"code","execution_count":null,"id":"1b708503-2ff9-4584-9d73-40990b3572f8","metadata":{"id":"1b708503-2ff9-4584-9d73-40990b3572f8"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"f42501fc-b573-4893-a7c4-5e280dfdaf09","metadata":{"id":"f42501fc-b573-4893-a7c4-5e280dfdaf09"},"source":["## Define Model"]},{"cell_type":"code","execution_count":8,"id":"f9a66615","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["709ae94045ca4d8a90f742789616af7f","59f7558a2f0947078751b964ff6b962b","19f5a019b36c4f57adee2740d73df296","2cd1c44f710849aeb45acfb184da97e6","4e1eaf4516e44ab0a6727537ed73f89a","461f336e9389411f8a232a73f96d7f52","0b60bdf3735e4f9486c712d2c3b8659a","92356a57b3c94c8abf95840140f22bf2","10f68f81f8c14c419358591ed8c33675","f81cd98798ae4d06a9a99694ac98b825","1cea88384896468bac22ae644aeb709a","3fa5d5af751b411eba0a7659256075f5","735c490deae74b65af73251233f9add2","565c7af21cb1441cbd300e6e1a16bcb1","6266a845cd7b47129a18fd97468a774e","bc43253ceb1347b7becc86f2818a2c71","73e96249e41745ab8bd6631fb97bbcbc","f03e354c167947e09f98a6bdb753c2c9","7043642143a54a41a831ef6c909be4f2","f1a4bce3a66e40a790a8240827f010a9","d617cef5996d4526a972a7d932d9ee0f","a2ca1b47107f42cab1d1d1329d1f41e4"]},"executionInfo":{"elapsed":15756,"status":"ok","timestamp":1690016408623,"user":{"displayName":"박상우(인공지능융합대학 컴퓨터과학과)","userId":"12478114581481068237"},"user_tz":-540},"id":"f9a66615","outputId":"df2643a8-0180-4883-ad98-51bd13015eaf"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading (…)lve/main/config.json: 100%|██████████| 6.57k/6.57k [00:00<?, ?B/s]\n","c:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","Downloading pytorch_model.bin: 100%|██████████| 375M/375M [00:38<00:00, 9.64MB/s] \n"]},{"data":{"text/plain":["SamModel(\n","  (shared_image_embedding): SamPositionalEmbedding()\n","  (vision_encoder): SamVisionEncoder(\n","    (patch_embed): SamPatchEmbeddings(\n","      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","    )\n","    (layers): ModuleList(\n","      (0-11): 12 x SamVisionLayer(\n","        (layer_norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (attn): SamVisionAttention(\n","          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","          (proj): Linear(in_features=768, out_features=768, bias=True)\n","        )\n","        (layer_norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): SamMLPBlock(\n","          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          (act): GELUActivation()\n","        )\n","      )\n","    )\n","    (neck): SamVisionNeck(\n","      (conv1): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (layer_norm1): SamLayerNorm()\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (layer_norm2): SamLayerNorm()\n","    )\n","  )\n","  (prompt_encoder): SamPromptEncoder(\n","    (shared_embedding): SamPositionalEmbedding()\n","    (mask_embed): SamMaskEmbedding(\n","      (activation): GELUActivation()\n","      (conv1): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n","      (conv2): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n","      (conv3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (layer_norm1): SamLayerNorm()\n","      (layer_norm2): SamLayerNorm()\n","    )\n","    (no_mask_embed): Embedding(1, 256)\n","    (point_embed): ModuleList(\n","      (0-3): 4 x Embedding(1, 256)\n","    )\n","    (not_a_point_embed): Embedding(1, 256)\n","  )\n","  (mask_decoder): SamMaskDecoder(\n","    (iou_token): Embedding(1, 256)\n","    (mask_tokens): Embedding(4, 256)\n","    (transformer): SamTwoWayTransformer(\n","      (layers): ModuleList(\n","        (0-1): 2 x SamTwoWayAttentionBlock(\n","          (self_attn): SamAttention(\n","            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n","            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n","          )\n","          (layer_norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","          (cross_attn_token_to_image): SamAttention(\n","            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n","            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n","            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n","            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n","          )\n","          (layer_norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","          (mlp): SamMLPBlock(\n","            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n","            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n","            (act): ReLU()\n","          )\n","          (layer_norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","          (layer_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n","          (cross_attn_image_to_token): SamAttention(\n","            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n","            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n","            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n","            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n","          )\n","        )\n","      )\n","      (final_attn_token_to_image): SamAttention(\n","        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n","        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n","        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n","        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n","      )\n","      (layer_norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (upscale_conv1): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n","    (upscale_conv2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n","    (upscale_layer_norm): SamLayerNorm()\n","    (activation): GELU(approximate='none')\n","    (output_hypernetworks_mlps): ModuleList(\n","      (0-3): 4 x SamFeedForward(\n","        (activation): ReLU()\n","        (proj_in): Linear(in_features=256, out_features=256, bias=True)\n","        (proj_out): Linear(in_features=256, out_features=32, bias=True)\n","        (layers): ModuleList(\n","          (0): Linear(in_features=256, out_features=256, bias=True)\n","        )\n","      )\n","    )\n","    (iou_prediction_head): SamFeedForward(\n","      (activation): ReLU()\n","      (proj_in): Linear(in_features=256, out_features=256, bias=True)\n","      (proj_out): Linear(in_features=256, out_features=4, bias=True)\n","      (layers): ModuleList(\n","        (0): Linear(in_features=256, out_features=256, bias=True)\n","      )\n","    )\n","  )\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model = SamModel.from_pretrained(\"facebook/sam-vit-base\")\n","\n","# make sure we only compute gradients for mask decoder\n","for name, param in model.named_parameters():\n","  if name.startswith(\"vision_encoder\") or name.startswith(\"prompt_encoder\"):\n","    param.requires_grad_(False)\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":9,"id":"27cd74b6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27cd74b6","outputId":"5685c691-b227-48b4-f1b4-e6444b7b39f8"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/536 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["[  0   0   0 ... 834 834 834]\n","[555 556 557 ... 459 460 461]\n","[  21   21   21 ... 1023 1023 1023]\n","[617 618 619 ... 786 787 788]\n","[  15   15   15 ... 1023 1023 1023]\n","[423 424 425 ... 791 792 793]\n","[   0    0    0 ... 1023 1023 1023]\n","[25 26 27 ... 83 84 85]\n","[   0    0    0 ... 1023 1023 1023]\n","[ 96  97  98 ... 786 787 788]\n","[   0    0    0 ... 1023 1023 1023]\n","[758 759 760 ...  92  93  94]\n","[   0    0    0 ... 1023 1023 1023]\n","[683 684 685 ... 616 617 618]\n","[   0    0    0 ... 1023 1023 1023]\n","[  0   1   2 ... 942 943 944]\n","[   0    0    0 ... 1023 1023 1023]\n","[430 431 432 ... 446 447 448]\n","[  0   0   0 ... 970 970 971]\n","[467 468 469 ... 879 880 880]\n","[   3    3    3 ... 1023 1023 1023]\n","[ 38  39  40 ... 867 868 869]\n","[  2   2   2 ... 788 788 789]\n","[356 357 358 ... 890 891 887]\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/536 [00:22<?, ?it/s]\n"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 9.00 GiB (GPU 0; 12.00 GiB total capacity; 19.96 GiB already allocated; 0 bytes free; 20.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m masks \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 16\u001b[0m outputs \u001b[39m=\u001b[39m model(pixel_values\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mpixel_values\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device),\n\u001b[0;32m     17\u001b[0m               input_boxes\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39minput_boxes\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device),\n\u001b[0;32m     18\u001b[0m               multimask_output\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     20\u001b[0m predicted_masks \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mpred_masks\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m loss \u001b[39m=\u001b[39m seg_loss(predicted_masks, masks\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n","File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\transformers\\models\\sam\\modeling_sam.py:1368\u001b[0m, in \u001b[0;36mSamModel.forward\u001b[1;34m(self, pixel_values, input_points, input_labels, input_boxes, input_masks, image_embeddings, multimask_output, attention_similarity, target_embedding, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1365\u001b[0m vision_hidden_states \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1367\u001b[0m \u001b[39mif\u001b[39;00m pixel_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     vision_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvision_encoder(\n\u001b[0;32m   1369\u001b[0m         pixel_values,\n\u001b[0;32m   1370\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1371\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1372\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1373\u001b[0m     )\n\u001b[0;32m   1374\u001b[0m     image_embeddings \u001b[39m=\u001b[39m vision_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1376\u001b[0m     \u001b[39mif\u001b[39;00m output_hidden_states:\n","File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\transformers\\models\\sam\\modeling_sam.py:1057\u001b[0m, in \u001b[0;36mSamVisionEncoder.forward\u001b[1;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1052\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m   1053\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m   1054\u001b[0m         hidden_states,\n\u001b[0;32m   1055\u001b[0m     )\n\u001b[0;32m   1056\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1057\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(hidden_states, output_attentions\u001b[39m=\u001b[39;49moutput_attentions)\n\u001b[0;32m   1059\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1061\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n","File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\transformers\\models\\sam\\modeling_sam.py:943\u001b[0m, in \u001b[0;36mSamVisionLayer.forward\u001b[1;34m(self, hidden_states, output_attentions)\u001b[0m\n\u001b[0;32m    940\u001b[0m     height, width \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], hidden_states\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\n\u001b[0;32m    941\u001b[0m     hidden_states, padding_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_partition(hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size)\n\u001b[1;32m--> 943\u001b[0m hidden_states, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[0;32m    944\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m    945\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    946\u001b[0m )\n\u001b[0;32m    947\u001b[0m \u001b[39m# Reverse window partition\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n","File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\transformers\\models\\sam\\modeling_sam.py:846\u001b[0m, in \u001b[0;36mSamVisionAttention.forward\u001b[1;34m(self, hidden_states, output_attentions)\u001b[0m\n\u001b[0;32m    843\u001b[0m attn_weights \u001b[39m=\u001b[39m (query \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale) \u001b[39m@\u001b[39m key\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    845\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_rel_pos:\n\u001b[1;32m--> 846\u001b[0m     attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_decomposed_rel_pos(\n\u001b[0;32m    847\u001b[0m         attn_weights, query, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrel_pos_h, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrel_pos_w, (height, width), (height, width)\n\u001b[0;32m    848\u001b[0m     )\n\u001b[0;32m    850\u001b[0m attn_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(attn_weights, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(query\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    852\u001b[0m attn_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(attn_weights, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n","File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\DeMa\\Lib\\site-packages\\transformers\\models\\sam\\modeling_sam.py:828\u001b[0m, in \u001b[0;36mSamVisionAttention.add_decomposed_rel_pos\u001b[1;34m(self, attn, query, rel_pos_h, rel_pos_w, q_size, k_size)\u001b[0m\n\u001b[0;32m    826\u001b[0m rel_w \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mbhwc,wkc->bhwk\u001b[39m\u001b[39m\"\u001b[39m, reshaped_query, relative_position_width)\n\u001b[0;32m    827\u001b[0m attn \u001b[39m=\u001b[39m attn\u001b[39m.\u001b[39mreshape(batch_size, query_height, query_width, key_height, key_width)\n\u001b[1;32m--> 828\u001b[0m attn \u001b[39m=\u001b[39m attn \u001b[39m+\u001b[39;49m rel_h[:, :, :, :, \u001b[39mNone\u001b[39;49;00m] \u001b[39m+\u001b[39;49m rel_w[:, :, :, \u001b[39mNone\u001b[39;49;00m, :]\n\u001b[0;32m    829\u001b[0m attn \u001b[39m=\u001b[39m attn\u001b[39m.\u001b[39mreshape(batch_size, query_height \u001b[39m*\u001b[39m query_width, key_height \u001b[39m*\u001b[39m key_width)\n\u001b[0;32m    830\u001b[0m \u001b[39mreturn\u001b[39;00m attn\n","\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.00 GiB (GPU 0; 12.00 GiB total capacity; 19.96 GiB already allocated; 0 bytes free; 20.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["import monai\n","seg_loss = monai.losses.DiceCELoss(sigmoid=True, squared_pred=True, reduction='mean')\n","# loss function과 optimizer 정의\n","criterion = torch.nn.BCEWithLogitsLoss()\n","Dice_Loss = smp.losses.DiceLoss(mode='binary')\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","\n","# training loop\n","model.train()\n","for epoch in range(5):  # 10 에폭 동안 학습합니다.\n","    train_loss = 0\n","    for input in tqdm(train_dataloader):\n","        masks = input[\"mask\"].float().to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(pixel_values=input[\"pixel_values\"].to(device),\n","                      input_boxes=input[\"input_boxes\"].to(device),\n","                      multimask_output=False)\n","\n","        predicted_masks = outputs.pred_masks.squeeze(1)\n","        loss = seg_loss(predicted_masks, masks.unsqueeze(1))\n","        score = 1 - loss\n","        print(\"dice score result: \")\n","        print(score)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        torch.cuda.empty_cache()\n","\n","    val_loss = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for val_input in tqdm(validation_dataloader):\n","            masks = val_input[\"mask\"].float().to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(pixel_values=val_input[\"pixel_values\"].to(device),\n","                      input_boxes=val_input[\"input_boxes\"].to(device),\n","                      multimask_output=False)\n","\n","            validation_predicted_masks = outputs.pred_masks.squeeze(1)\n","            loss = seg_loss(validation_predicted_masks, masks.unsqueeze(1))\n","            score = 1- loss\n","            print(score.cpu)\n","            val_loss += loss.item()\n","\n","\n","    print(f'Epoch {epoch+1}, Loss: {train_loss/len(train_dataloader)}')\n","    print(f'Epoch {epoch+1}, Loss: {val_loss/len(validation_dataloader)}')"]},{"cell_type":"markdown","id":"a0895765-fba0-4fd9-b955-a6c0e43012e9","metadata":{"id":"a0895765-fba0-4fd9-b955-a6c0e43012e9"},"source":["## Model Train"]},{"cell_type":"code","execution_count":null,"id":"63efb381-98c6-4d9b-a3b6-bd11c7fa8c41","metadata":{"id":"63efb381-98c6-4d9b-a3b6-bd11c7fa8c41"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"c32eb51c-a3fe-4e11-a616-3a717ba16f7e","metadata":{"id":"c32eb51c-a3fe-4e11-a616-3a717ba16f7e"},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"id":"47c3b742","metadata":{"id":"47c3b742"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"43df5162","metadata":{"id":"43df5162"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"36c2cbbb-04f1-4f9c-b4df-4b744dfce046","metadata":{"id":"36c2cbbb-04f1-4f9c-b4df-4b744dfce046"},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"id":"f6543d00-32b3-4f2d-a572-d0879fd0a497","metadata":{"id":"f6543d00-32b3-4f2d-a572-d0879fd0a497"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"da10cb6f-0826-4755-a376-97b695ae8f86","metadata":{"id":"da10cb6f-0826-4755-a376-97b695ae8f86"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5feb78aa","metadata":{"id":"5feb78aa"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"74a040db","metadata":{"id":"74a040db"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b60bdf3735e4f9486c712d2c3b8659a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10f68f81f8c14c419358591ed8c33675":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19f5a019b36c4f57adee2740d73df296":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92356a57b3c94c8abf95840140f22bf2","max":6566,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10f68f81f8c14c419358591ed8c33675","value":6566}},"1cea88384896468bac22ae644aeb709a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cd1c44f710849aeb45acfb184da97e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f81cd98798ae4d06a9a99694ac98b825","placeholder":"​","style":"IPY_MODEL_1cea88384896468bac22ae644aeb709a","value":" 6.57k/6.57k [00:00&lt;00:00, 622kB/s]"}},"3fa5d5af751b411eba0a7659256075f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_735c490deae74b65af73251233f9add2","IPY_MODEL_565c7af21cb1441cbd300e6e1a16bcb1","IPY_MODEL_6266a845cd7b47129a18fd97468a774e"],"layout":"IPY_MODEL_bc43253ceb1347b7becc86f2818a2c71"}},"461f336e9389411f8a232a73f96d7f52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1eaf4516e44ab0a6727537ed73f89a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51f3e742ffd84793b5dfcb319dfc6677":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61956ae95d074178af64b5e533cbe4da","placeholder":"​","style":"IPY_MODEL_6ec2281e00e84edba6db004e52eb6a82","value":"Downloading (…)rocessor_config.json: 100%"}},"565c7af21cb1441cbd300e6e1a16bcb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7043642143a54a41a831ef6c909be4f2","max":375050165,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1a4bce3a66e40a790a8240827f010a9","value":375050165}},"59f7558a2f0947078751b964ff6b962b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_461f336e9389411f8a232a73f96d7f52","placeholder":"​","style":"IPY_MODEL_0b60bdf3735e4f9486c712d2c3b8659a","value":"Downloading (…)lve/main/config.json: 100%"}},"61956ae95d074178af64b5e533cbe4da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62480e98a3fa4cf3a2de6331f06790a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6266a845cd7b47129a18fd97468a774e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d617cef5996d4526a972a7d932d9ee0f","placeholder":"​","style":"IPY_MODEL_a2ca1b47107f42cab1d1d1329d1f41e4","value":" 375M/375M [00:05&lt;00:00, 63.0MB/s]"}},"6ec2281e00e84edba6db004e52eb6a82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7043642143a54a41a831ef6c909be4f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"709ae94045ca4d8a90f742789616af7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_59f7558a2f0947078751b964ff6b962b","IPY_MODEL_19f5a019b36c4f57adee2740d73df296","IPY_MODEL_2cd1c44f710849aeb45acfb184da97e6"],"layout":"IPY_MODEL_4e1eaf4516e44ab0a6727537ed73f89a"}},"735c490deae74b65af73251233f9add2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73e96249e41745ab8bd6631fb97bbcbc","placeholder":"​","style":"IPY_MODEL_f03e354c167947e09f98a6bdb753c2c9","value":"Downloading pytorch_model.bin: 100%"}},"738e5be11e0e453b92fdaaa92d9d4cb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73e96249e41745ab8bd6631fb97bbcbc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92356a57b3c94c8abf95840140f22bf2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2ca1b47107f42cab1d1d1329d1f41e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab2e1240643249de8be662a5f5ddd481":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b237982e68604a219a327957adf3dbd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51f3e742ffd84793b5dfcb319dfc6677","IPY_MODEL_d6bdb4107af24ca8b73bb3f405b3cbec","IPY_MODEL_de0ab2ee3636441aafbec0cd680b76eb"],"layout":"IPY_MODEL_62480e98a3fa4cf3a2de6331f06790a0"}},"b6a8b52314d74cae87960c26876066bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc43253ceb1347b7becc86f2818a2c71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d617cef5996d4526a972a7d932d9ee0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6bdb4107af24ca8b73bb3f405b3cbec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffe648c796574e54a65e050e60774650","max":466,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab2e1240643249de8be662a5f5ddd481","value":466}},"de0ab2ee3636441aafbec0cd680b76eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6a8b52314d74cae87960c26876066bb","placeholder":"​","style":"IPY_MODEL_738e5be11e0e453b92fdaaa92d9d4cb7","value":" 466/466 [00:00&lt;00:00, 38.7kB/s]"}},"f03e354c167947e09f98a6bdb753c2c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1a4bce3a66e40a790a8240827f010a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f81cd98798ae4d06a9a99694ac98b825":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffe648c796574e54a65e050e60774650":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":5}
